<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Jinwoo Kim â€” Autonomous Driving Research Development</title>
    <meta name="description" content="Autonomous Driving Research Development Â· Vision-Language Models Â· Large Language Models Â· Publications, Patents, Projects, and Research Videos." />

    <!-- Minimal CSS for left-sidebar academic layout -->
    <style>
      :root{--text:#0f172a;--muted:#475569;--bg:#ffffff;--line:#e2e8f0;--link:#0ea5e9}
      @media (prefers-color-scheme: dark){:root{--text:#e2e8f0;--muted:#9ca3af;--bg:#0b1020;--line:#1f2937;--link:#38bdf8}}
      *{box-sizing:border-box}body{margin:0;font:16px/1.6 system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial,sans-serif;color:var(--text);background:var(--bg)}
      a{color:var(--link);text-decoration:none}a:hover{text-decoration:underline}
      .container{max-width:1100px;margin:0 auto;padding:24px}
      .grid{display:grid;grid-template-columns:320px 1fr;gap:32px}
      aside{position:sticky;top:24px;height:max-content;border:1px solid var(--line);border-radius:16px;padding:24px}
      .avatar{width:128px;height:128px;border-radius:16px;background:#eef2ff;display:block}
      .name{font-weight:800;font-size:22px;margin:8px 0 4px}
      .role{color:var(--muted)}
      .list-plain{list-style:none;padding:0;margin:16px 0 0;display:grid;gap:8px}
      .icon{width:18px;height:18px;opacity:.8;margin-right:8px;vertical-align:-3px}
      main section{border-bottom:1px solid var(--line);padding:24px 0}
      h2{font-size:22px;margin:0 0 12px}
      .news li{margin:4px 0}
      .pubs ol{padding-left:20px}
      .small{color:var(--muted);font-size:14px}
      footer{padding:28px 0;color:var(--muted)}
      /* mobile */
      @media (max-width:900px){.grid{grid-template-columns:1fr}aside{position:static}}
    </style>
  </head>
  <body>
    <div class="container">
      <div class="grid">
        <!-- Left sidebar -->
        <aside>
          <img class="avatar" src="assets/profile.jpg" alt="Profile photo placeholder" />
          <div class="name">Jinwoo Kim</div>
          <div class="role">Autonomous Driving Research Development</div>
          <div class="small">Daejeon, South Korea</div>

          <ul class="list-plain">
            <li>ğŸ™ <a href="https://github.com/jwkim81-ETRI">GitHub</a></li>
            <li>ğŸ”— <a href="https://www.linkedin.com/in/jinwoo-kim-836a9b56/">LinkedIn</a></li>
            <li>ğŸ§‘â€ğŸ“ <a href="https://scholar.google.com/citations?user=ygAVm3EAAAAJ&hl=en">Google Scholar</a></li>
          </ul>
        </aside>

        <!-- Right content -->
        <main>
          <section id="about">
            <p><strong>Senior researcher</strong> focusing on vision-language based, end-to-end intelligence for autonomous driving. I study perception-to-planning with <strong>multiâ€‘stage reasoning</strong>, <strong>HDâ€‘map aware action</strong>, and <strong>realâ€‘time inference</strong> under adverse weather/night/OOD conditions.</p>
          </section>

          <section id="news">
            <h2>News</h2>
            <ul class="news">
              <li>2024.09 â€” RoSA Dataset accepted to <em>ECCV Workshop</em>.</li>
              <li>2025 â€” Building VLMâ€‘based E2E driving stack with weather robustness and selective routing.</li>
            </ul>
          </section>

          <section id="interests">
            <h2>Research Interests</h2>
            <ul>
              <li>Visionâ€‘Language Planning (VLP), Endâ€‘toâ€‘End Autonomous Driving</li>
              <li>Robustness under weather/night/OOD; uncertainty</li>
              <li>Realâ€‘time inference, efficient CNN/VLM hybrid backbones</li>
              <li>Multiâ€‘stage reasoning, memory, selective routing</li>
              <li>HDâ€‘map aware action reasoning</li>
            </ul>
          </section>

          <section id="pubs" class="pubs">
            <h2>Publications</h2>
            <ol>
              <li>
                <strong>RoSA Dataset: Road Construction Zone Segmentation for Autonomous Driving</strong>
                <span class="small"> â€” ECCV Workshop, 2024â€‘09â€‘30</span>
                â€” <a href="https://www.springerprofessional.de/en/rosa-dataset-road-construct-zone-segmentation-for-autonomous-dri/51030158">Publisher</a>
              </li>
              <li>
                <strong>Multiâ€‘sensorâ€‘based Detection and Tracking of Moving Objects for Relative Position Estimation in Autonomous Driving Conditions</strong>
                <span class="small"> â€” Springer, 2020â€‘10â€‘01</span>
                â€” <a href="https://link.springer.com/article/10.1007/s11227-019-02811-y">Publisher</a>
              </li>
              <li>
                <strong>Fusion of Driverâ€‘information based Driver Status Recognition for Coâ€‘pilot System</strong>
                <span class="small"> â€” IEEE Intelligent Vehicles Symposium, 2016â€‘06â€‘21</span>
                â€” <a href="https://ieeexplore.ieee.org/document/7535573">IEEE Xplore</a>
              </li>
              <li>
                <strong>Multimodal Interface Based on Novel HMI UI/UX for Inâ€‘Vehicle Infotainment System</strong>
                <span class="small"> â€” ETRI Journal, 2015â€‘01â€‘01</span>
                â€” <a href="https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.15.0114.0076">ETRI Journal</a>
              </li>
            </ol>
          </section>

          <section id="patents">
            <h2>Patents</h2>
            <ul>
              <li><strong>System and Method for Fusion Recognition Using Active Stick Filter</strong> â€” US 11790555 (2023â€‘10â€‘17)</li>
              <li><strong>The Apparatus and Method for Driver Status Recognition Based on Driving Status Decision Information</strong> â€” JP 7154959 (2022â€‘10â€‘07)</li>
              <li><strong>Apparatus and Method of Learning Pose of Moving Object</strong> â€” US 10789717 (2020â€‘09â€‘29)</li>
              <li><strong>User Intention Analysis Apparatus and Method Based on Image Information of Threeâ€‘Dimensional Space</strong> â€” US 9886623 (2018â€‘02â€‘06)</li>
              <li><strong>System and Method for Learning Driving Information in Vehicle</strong> â€” US 9485474 (2016â€‘11â€‘01)</li>
              <li><strong>Method and Apparatus for Analyzing Concentration Level of Driver</strong> â€” US 9355546 (2016â€‘05â€‘31)</li>
              <li><strong>Augmented Reality Display System and Method for Vehicle</strong> â€” US 9075563 (2015â€‘07â€‘07)</li>
            </ul>
          </section>

          <section id="projects">
            <h2>Projects</h2>
            <ul>
              <li>Endâ€‘toâ€‘End Weatherâ€‘Robust Driving</li>
              <li>Selective Routing Planner</li>
              <li>Mapâ€‘aware Action Reasoner</li>
            </ul>
          </section>

          <section id="videos">
  <h2>Research Videos</h2>
  <div style="display:flex;gap:16px;flex-wrap:wrap">
    <a href="https://www.linkedin.com/feed/update/urn:li:activity:7318985849746964480/?originTrackingId=CSS3Pgt2RBeym8hrcGkSqQ%3D%3D" target="_blank">
      <img src="ADS5.jpg" alt="Autonomous Driving Demo Video" style="width:380px;border-radius:8px;border:1px solid #ddd">
    </a>
  </div>
</section>

          <footer>
            Â© <span id="year"></span> Autonomous Driving Research Development
          </footer>
        </main>
      </div>
    </div>
    <script>document.getElementById('year').textContent=new Date().getFullYear()</script>
  </body>
</html>
